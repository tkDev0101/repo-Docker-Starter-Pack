Docker Compose Transcripts


Transcript - Docker Compose in 12 Minutes
Transcript - Ultimate Docker Compose Tutorial


============================================================================================

Transcript - Docker Compose in 12 Minutes

Introduction
0:00
in the first video we learned that an
0:01
image is a template for the environment
0:03
that you want to run and when you run an
0:05
image you get a container we tried this
0:07
out by running a PHP image this was okay
0:10
for our very simple application but
0:11
imagine if you have something more
0:13
complicated let's work through an
0:15
example traditionally a big website like
0:17
an online store would be one big
0:19
application but a newer trend is to
0:21
split these big applications up into
0:23
smaller microservices the website can
0:26
then be quite minimal and it just makes
0:28
calls to other services to get
0:30
information or to ask them to do some
0:32
piece of work we're going to build a
0:34
really simple e-commerce website but
0:35
we're going to put the code that
0:36
provides the products and the product
0:39
information in its own microservice the
0:42
website will then use an API on the
0:43
product service to request the list of
0:45
products to show to the customer
0:47
something I touched on at the end of the
0:49
last video is how you should only have
0:51
one process per container so each
0:52
container should provide a single
0:55
service for this we'll want one
0:57
container running the website and one
0:59
container running the product service
1:02
they should be independent this means
1:03
that they can be written in different
1:05
languages but they do need to be able to
1:07
talk to each other but we'll get to that
1:08
bit later let's start with the product
Product Service
1:11
service I'm going to build this using
1:13
python I'm going to create a new
1:14
directory for this service called
1:17
Product and in here I'm going to write a
1:19
very simple python script I'll call it
1:22
api. py remember this is not a Python
1:25
tutorial so this is just going to be a
1:26
very quick example so this is going to
1:29
be the product service I want this to be
1:31
a simple restful API so I'm going to
1:34
import flask and flask restful and
1:36
instantiate these objects then I'm going
1:39
to have a product class which extends
1:41
resource and this is just going to have
1:43
a get method which will return some Json
1:48
so we want to sell some ice cream some
1:52
chocolate and we'll be healthy and sell
1:54
some fruit as well I'm going to add the
1:56
routin at the bottom and then finally
1:59
just some code to run the
2:03
application listening on Port 80 with
2:06
debug turned on obviously a real API
2:09
would return a lot more data than this
2:10
it would be a lot more thought out and a
2:12
lot better in general but this will do
Python
2:13
since I've used flask and flask restful
2:16
I'm going to add these to a
2:19
requirements.txt file so this is a list
2:21
of dependencies pip can then use this
2:23
file to install everything this is not
2:26
specific to Docker this is just a python
2:28
thing but now let's get this running in
2:30
a Docker container first I'm going to
2:32
make a Docker
2:34
file remembering back to the previous
2:36
video the first line needs to use the
2:38
from keyword to specify a base image
2:42
that we'll then build on top of there is
2:44
an official python image that we can use
2:46
we just want the latest version of
2:47
python and you'll notice it has these
2:50
onbuild tags it explains further down
2:53
the page that these ones automatically
2:54
install requirements from the
2:56
requirements.txt file this sounds very
2:58
useful for us it's as if I planned it in
3:01
advance so let's put this in our Docker
3:03
file from python colon then the tag
3:06
three on build next we want to copy the
3:09
source code into the image so we just
3:11
want to copy the current directory into
3:16
SL user sourcea I've chosen user Source
3:19
apppp because this is what the onbuild
3:21
image expects then we need to give this
3:23
a command to run when it starts I'm
3:25
using the command keyword and then this
3:27
weird array like syntax we can tell it
3:29
to to run Python and any subsequent
3:32
elements in this array are arguments
3:34
passed to python so we can just tell it
3:37
to run the script api. py so we already
3:40
know how to run this using Docker we do
3:42
Docker builds to create an image out of
3:44
the steps defined in the docker file and
3:47
then we do Docker run and add some
3:49
various arguments to specify ports and
3:52
mount volumes but you might find this
3:54
get a bit tedious and as we add more
3:56
containers running more of our services
3:58
building and starting each one
3:59
separately and making sure they can
4:01
communicate is just a pain this is where
4:04
Docker comp polls comes in Docker comp
4:06
PS lets us Define all of our services in
4:08
a configuration file and with one
4:10
command it'll spin up all of the
4:12
containers that we need the first thing
4:14
we want to do is make a file called
4:16
Docker compos and I'm going to do this
4:18
one directory up because this is going
4:20
to cover all of our services so it wants
4:22
to be called Docker hyphen compose and
4:25
it's a yaml file so the the extension is
4:27
yml in this file we start by specifying
4:30
the version of the compose file format
4:33
we do version colon and we're going to
4:36
go with three Docker has changed a lot
4:38
in the last few years and they keep
4:39
changing the way compos files have to be
4:41
written so this doesn't relate directly
4:43
to the version of Docker compos that you
4:45
have installed this is just the version
4:48
of the docker compul file format that
4:50
you wish to write in the latest version
4:53
right now is three there are subtle
4:54
differences between each version there's
4:56
no reason not to use the latest one
4:58
after this we specify our services so we
5:00
write services callon and we'll start
5:02
with product service so we give it a
5:04
name it can be anything you want first
5:07
we tell Docker compose what to build so
5:11
we use the build property and we give it
5:13
a directory containing the docker
5:15
compose file so the folder is called
5:16
Product we can see here that we've got
5:18
the folder called Product next to Docker
5:20
compost. yml the directories are
5:23
relative to where the docker compul file
5:25
is next we can specify volumes and this
5:27
is done as a list so you can have as
5:29
many as you want want the format is a
5:30
hyphen then a space and then the
5:33
directory on the host so your computer
5:35
so product and we want to mount that in/
5:39
user sourcea so of course the image when
5:42
it's built will already have the code
5:43
inside but mounting a volume makes
5:45
development easier because it'll see
5:47
Live code changes as they happen we can
5:50
do the same with ports to another list
5:53
our application is listening on Port 80
5:57
so we want to map something to Port 80
5:59
so to the port on the host we'll use
6:02
50001 this can be anything you could map
6:04
it to Port 80 but it might clash with a
6:07
web server already installed on your
6:09
operating system or something else using
6:11
Port 80 easier just to avoid it we'll go
6:14
for
6:14
50001 um and connect that to Port 80 in
6:17
the container and that's all we need
6:19
this is the stuff that we would have
6:21
previously specified in the docker run
6:22
command but in a much easier format and
6:25
saved in a configuration file to run
6:28
this we go back to the terminal and type
6:30
Docker hyphen compul up now you
6:32
obviously want Docker to be running
6:34
already I'm assuming you have Docker for
6:36
Mac or Docker for windows installed and
6:38
that app is already open and as long as
6:40
we're in the same directory as the
6:42
docker compulse file it'll automatically
6:44
start the services it'll build the
6:46
images if necessary in this case it's
6:47
going to download uh that python image
6:50
we found on the docker Hub the onbuild
6:52
trigger will run here automatically and
6:53
install our flask dependencies and then
6:56
finally it'll run our container so if we
6:58
go to a web browser we we can go to
7:00
Local Host 5000
7:03
And1 and it works it gives us our
7:05
adjacent array of products if we make a
7:07
change to the product service let's say
7:09
we also sold eggs because we got the
7:12
volume mounted python sees the change it
7:14
detects this and reloads so now when we
7:17
refresh we get eggs as well okay we can
7:19
press contrl C in the terminal to stop
7:22
that container now we want to build the
7:23
website which will use this product
7:25
service so make a new folder called
7:27
website I'm going to write this this in
PHP
7:29
PHP again it's going to be very quick
7:31
and simple we'll make a file called
7:34
index.php We'll add a little bit of
7:38
HTML what I want to achieve here is a
7:40
bullet point list where each element in
7:42
the list is a product from the product
7:44
service so let's open PHP tags and I can
7:48
use this function called file get
7:50
contents I wouldn't recommend this in
7:51
production but it works for an example
7:53
this function you give it a URL and it
7:55
returns a string containing the contents
7:57
of whatever is at that URL now we get to
8:00
the interesting question of which URL to
8:02
use when we access the product service
8:04
locally we can use Local Host colon
8:06
50001 this won't work within a Docker
8:09
container because for the container
8:11
Local Host will be itself conveniently
8:14
for us Docker compost creates a virtual
8:17
Network for all of the containers so by
8:19
default each container can access all of
8:22
the others defined in the compos file
8:24
and their host names match the service
8:27
name which is nice so we called it
8:29
product hyphen service this is the host
8:32
name that we can use in our PHP script
8:34
so we can do HTTP col product service
8:38
and when we use Docker comp plls to run
8:40
this that will resolve to the product
8:42
service container so dollar Json will
8:45
contain that roll Json straight from the
8:47
product service we can decode it then we
8:49
can pull the products out of it and loop
8:52
through them and Echo each one in a
8:55
bullet point list item for this we could
8:57
write a Docker file again but instead
8:58
I'm going to demonstrate at another way
9:00
to use Docker comp polls we're going to
9:02
make a new service called website and
9:04
instead of specifying a directory to
9:07
build with a Docker file inside we can
9:09
just use the image property and give it
9:11
a name of an image so this could be an
9:13
image we've built previously ourselves
9:15
or it can be an image straight from the
9:17
docker hub from the previous tutorial we
9:19
know that there's a PHP image that we
9:22
can use and we want the version that
9:23
comes with Apache next we want volumes
9:26
so with the product service this will
9:29
was just for convenience because we made
9:31
a custom image which included the source
9:33
code this time we're getting the image
9:35
straight from the docker Hub so it's not
9:36
going to include our source code so we
9:38
we need the volume here for anything to
9:41
happen so here we want the website
9:43
folder to go in /var/www/media
9:59
so we know that the website's not going
10:01
to work unless the product service is
10:03
running that c to file get content would
10:05
just fail so we can tell Docker comp
10:07
that the website depends on the product
10:09
service so it just uses this name here
10:12
you can list multiple things that a
10:13
service depends on so now when we do
10:15
Docker compos up it's going to pull that
10:18
PHP image then it'll start the product
10:20
service then it will start the website
10:22
so when we go to Local Host 5000 um it
10:25
doesn't work what's gone wrong we need
10:28
to pluralize product
10:30
products so now when we refresh welcome
10:32
to my shop then the PHP script made a
10:34
call to the product service decoded the
10:35
Json and it displays it on the page we
10:38
can see how easy it is to start all of
10:40
these services and have them communicate
10:42
it's all defined in this config file
10:44
which is easy to change and saved
10:46
alongside the code so you could Commit
10:48
This to GitHub for example then anyone
10:50
else who works on the project just has
10:52
to run Docker compos up and everything
10:55
will happen automatically they don't
10:56
have to go to any effort to configure a
10:58
Dev en environment another feature of
11:00
Docker compos is detached mode um you
11:03
can do Docker compos up- D and this will
11:08
run it in the background so I can
11:10
continue to do work um we can type
11:12
Docker PS to see that those containers
11:14
are running so we've got the the PHP one
11:17
and the product service one running
11:19
there this also shows us that the PHP
11:21
image is unmodified straight from the
11:24
docker Hub whereas the product service
11:26
is using our Custom Image which it is
11:28
named tutorial _ product service you
11:31
obviously can't do control C anymore to
11:33
to stop them um but you can do Docker
11:36
compose
11:39
stop I hope you see the power of Docker
11:41
compos and I hope that this helps you
11:43
out when running Docker containers if
11:45
you've got any questions or feedback
11:47
please do leave a comment if this was
11:49
useful I'd really appreciate a like and
11:50
if you want to see more of this then do
11:52
subscribe in a future video we'll look
11:54
at Docker deployment options thanks for
11:57
watching


============================================================================================

Transcript - Ultimate Docker Compose Tutorial


Intro and Course Overview
0:00
in this video you will learn everything you need to know to get started with using Docker compose we'll go over what
0:07
it is exactly what problems Docker compose was designed to solve its common
0:12
use cases and of course we will do some Hands-On demos to learn actually using
0:17
Docker compose in practice I am super excited to teach you all this so let's
0:22
jump into it now in order to understand Docker compos you need to First understand
Pre-Requisites to learn Docker Compose
0:29
docker and have some basic experience with it if you don't I recommend you pause and watch my Docker crash course
0:36
first and then continue with this one because Docker compost is essentially a tool that is supposed to manage and work
0:44
with Docker containers so you need to understand that part first so that you understand the context for learning
0:50
Docker compost so in the docker video I break down what the containers are what images are what problems Docker solves
0:57
and what use case it it has dockerizing your application with Docker file and all the concepts you need to understand
1:02
Docker itself so based on that knowledge we can Now understand why Docker compos was created along with Docker and when
1:09
we want to use it now applications are composed of many
What is Docker Compose
1:16
different parts you can have apis databases any Services your application
1:21
depends on and even within the application you may have a microservice application which is basically an
1:28
application broken down into multip micro applications or microservices and
1:33
when you're creating containerized applications all of these different application components must be deployed
1:40
and run together because they have dependencies on each other so basically you have a set of containers which are
1:47
running different services and applications within them that need to run together that need to talk to each
1:53
other and so on so Docker compose is basically a tool that allows you to
1:59
Define and run multiple services and applications that belong together in one
2:05
environment so simply put if you want to deploy multiple Docker containers where each container may have its different
2:11
configuration options you can use Docker compose to do this to manage these
2:16
containers way more easily now this is just a general definition to give you
2:22
some idea of what Docker compose is but of course we want to understand this with specific examples and specific
2:30
demonstration so that you really understand these Concepts and the actual use cases of using doer compose and not
2:38
just a general abstract explanation of what it is and because of that we're going to jump right into that demo where
2:45
I'm going to explain the concepts the use cases using those demonstrations so let's get
2:51
started as a first step we're going to start two Services as Docker containers
Demo - Without Docker Compose
2:57
using just the docker command so we're not going to use Docker compos as a first step so we can see and compare the
3:03
before after States first we're going to create a Docker Network where these two containers will run and talk to each
3:09
other using just the container name and then we're going to start two containers one is going to be a mongodb container
3:16
and another one is going to be Express container which is basically a UI for the mongodb database very simple
3:23
use case and we're going to run both containers using Docker run commands so that's our first very simple
3:29
demonstration let's go ahead and do that so I'm going to switch to a terminal
3:34
because we're going to execute those docket run commands on the terminal and you probably see this is a fancy fun
3:40
looking terminal that I have been using since recently and this is an application or a terminal app called
3:47
warp which is actually a sponsor of this video I actually played around with warp
3:53
and love using it it's free it's easy to install on your computer so I will be using warp throughout the entire day
3:59
demo because it also helps highlight some of the commands and stuff better so it's going to be easier for you guys to
4:04
follow what I'm showing you however if you want to install warp yourself on your computer you can go ahead and check
4:10
out the link to get started in the video description where I'm going to provide all the relevant links for this crash
4:16
course including the warp installation so to run our Docker containers of
4:21
course we need to have Docker installed and running so I'm going to start up Docker and then we can start the
4:27
containers so the docker service is up and running let's go ahead and create
4:33
the docker Network first so I'm going to do Docker Network and since we're going
4:38
to run mongodb and Express containers we can call this network Network and let's create and now
4:47
if I do Docker Network LS so basically list all the networks available these
4:53
are the default ones basically that you get out of the box when you install Docker and this is the Network
4:58
that we just created awesome so the network is there now let's run our two
5:03
containers and if you know Docker if you followed my Docker crash course basically you know all this stuff Docker
5:10
run and we're going to execute this in the background and we have the and
5:17
Express image documentation so we can actually reference
5:23
this so first I'm going to define the port uh mongodb's default Port is $27
5:30
07 so we're going to map that to the same port so we we're going to bind that
5:36
to the same port on the host then we're going to define those two environment variables to basically set the admin or
5:44
the root user and password so we're going to copy those and we're going to
5:49
call this
5:56
admin and this is some password we're going to set this to super secret so all
6:03
these should be actually be a refresher from Docker we also want to specify that
6:08
it should run in this network network so we're going to do
6:16
Network run in this one we're also going to name our
6:22
container instead of having Docker just create a random container name so we're
6:28
going to call this DB and finally we need to specify the
6:34
image right and this is the name of the image and that's basically our Docker
6:41
command so I'm going to execute and this will fetch or pull the
6:47
latest image from dockerhub repository and run it in a detached
6:57
mode perfect so we should have have our mongodb container running and now let's
7:03
start Express container and I can actually bring up my previous command
7:08
and we're going to adjust it for the Express right here we see that
7:14
Express is running on port 8080 so that's what we're going to set here
7:19
there you go we also have different environment variables so basically
7:25
Express is just a UI for mongodb and in order for us to use it it needs to
7:33
connect and authenticate with mongodb so we need to provide it the credentials as well that we set for mongodb database
7:41
and we're passing those also as environment variables but in this case the environment variables are named
7:47
differently so that's what we're using referring to the official documentation which you always should do to get the
7:52
most up toate data and you also see the default values for those environment variables the port is correct because
7:59
that's what we binded it to on our host and mongod to be server which is going to be the mongod to be container name in
8:06
our case it's different because we called our container mongod beam so we're going to set this environment
8:11
variable as well so right here I'm going to add this and we're going to set these to mongodb let's not forget the
8:19
backwards slash here so the ports are correct the environment variables are correct we are going to run it also in
8:26
the Network we're going to name this Express so that's going to be the name of the container and let's see
8:33
what the actual name of the image is just going to copy that so that I don't make spelling mistake and that's it
8:40
let's execute this as well and seems like it started without
8:48
any problems let's see perfect it's running and now to test that it was
8:54
actually able to connect without any issues to the mongodb database container
9:00
we're going to access it in our browser so we opened it on Port 881 on our host
9:09
and it is asking for basic authentication in the browser and we can actually get those in the locks let's do
9:16
that do logs of Express and here we have
9:23
the credentials so admin pass should work
9:31
and there you go so that's a test and a proof that it was able to connect to our
9:37
database since we didn't have any connection errors here and we're able to access the application here so this was
9:44
basically just to demonstrate how you would start containers that belong to each other so Express container
9:50
actually depends on mongodb because we don't need it without the database in the background so kind of start
9:56
containers that belong together that should run together using just plain Docker and also
10:02
starting them in the same network so they can talk to each other in that isolated virtual Network now obviously
Why Docker Compose
10:10
these are just two containers but if we have microservice application with 10 different services that has a messaging
10:15
service maybe two databases that it belongs to maybe those databases have their own UI services that we want to
10:22
run in addition so now these are lots of containers that we need to start and
10:28
manage using just plain Docker commands and now imagine if you need to stop those containers because you don't want
10:34
to have them running all the time or you want to make changes and restart them again this is going to be a lot of
10:40
manual tedious work and you don't want to execute these commands all the time on the command line terminal especially
10:47
when you have tens of containers so you want an easier way to manage to stop
10:52
start configure containers that you want to start together and that's exactly where Docker compose comes into the
10:59
picture so Docker compos basically makes running multiple Docker containers with all this configuration that we just
11:05
defined on those containers so you have the environment variables you have ports maybe you have multiple ports on the
11:11
same container same application that you want to open maybe you want to configure additional volumes for example for data
11:17
persistence so that's the main use case of Docker compose so with Docker compose
11:22
basically you have a file a yaml file where you define all this configuration
11:28
a list of contain ERS or services that you want to start together and all their configuration in one central place in a
11:34
file that you can modify configure and use to start and stop those containers
11:40
so let's see how the file looks like and how these Docker run commands actually map to the docker compost so how can we
11:47
migrate or map all of these and write a Docker compost file that starts those
11:53
two containers with exactly the same configuration that we defined here
From Docker Commands To Compose File
11:59
so this is a Docker run command of the mongod beam that we executed previously so basically with Docker compos file
12:06
what we can do is we take the whole command with this configuration and map it into a file so we have that command
12:13
defined in a structured way so if you have let's say 10 20 Docker containers that you want to run for your
12:19
application and they all need to talk to each other and interact with each other you can basically write all the Run
12:26
commands for each container in a structured way in Docker compose and Define the entire configuration there
12:32
and this is how the structure in Docker compose will actually look like so the first two lines are required attributes
12:39
of Docker compose file with the first line we basically Define the version of Docker compose which is the latest
12:45
version that should be compatible with the docker compose that you have installed locally so the latest Docker
12:51
compose tool installed on your computer will be able to read the latest Docker compose file version and then we have
12:58
the services and Docker compose is super simple Services is basically an attribute where you can list all the
13:05
services or all the containers that you want to run as part of this doer compos file so in this case the first service
13:11
we want to Define is mongodb and that Maps actually to The Container name or rather this is going to be part of the
13:17
container name when the services are created as Docker containers and for each service like Mong TB we have all
13:25
the configuration for that specific container so the first one is obviously image because we are building the
13:31
container from the image so we need to know which image that container is going to be built from and of course you can
13:36
specify version Tech here next to the name the next one is the list of ports
13:42
because you can open multiple ports on a container if there are multiple processes running inside the container
13:47
but mostly you would just have one so this is where we Define the port mappings so mapping a container port to
13:54
the host so just like in Docker command the first Port refers to the host the second one refers to the port inside
14:00
container then we have the environment variables listed under an environment
14:06
attribute like this and this is actually how the structure of Docker compose
14:11
looks like for one specific command now let's actually add the second container command for Express and how that
14:18
Maps into our Docker compost file so again we have the service which we can call Express and by the way the
14:25
service names are completely up to you you can call them whatever you want just like the container names you can call
14:30
the containers whatever you want and under that Express we have the same exact configuration options we have
14:37
the image which refers to Express image again you can have a TCH here if you want to have a specific one then we
14:43
have the port and all the environment variables that we defined with Docker run command under the environment
14:49
attribute and this is how Docker compos will look like with multiple Services
14:54
defined inside so basically Docker compos is just a structured way to contain very normal common Docker
15:02
commands and of course it's going to be easier for you to edit this file if you want to change some variables or if you
15:08
want to change the ports or if you want to add more services with those services
15:13
and as part of everything as code Trend dock compose is basically a code that
15:19
defines how your services should run within a file that you can check in to a
15:24
code repository and multiple people can work on it together compared to a command that you just
15:31
execute manually on your computer with individual Docker run commands the final thing here which you may already noticed
15:38
is the network configuration is not defined in the docker compost so we didn't map that part from the docker run
15:45
commands so this Monga Network that we created we don't have to explicitly create or Define it in Docker compost
15:51
because Docker compose will actually take care of creating a shared network
15:56
for all the containers from from the services list that it's going to run when we execute this file so we don't
16:03
have to create the network specifically and then specify that all the containers run in that Network Docker compose will
16:09
automatically take care of it and we're actually going to see that in action right away so now let's actually go and
Create Compose File and start application
16:15
create a Docker compos file in a code editor so in this projects directory so
16:21
basically where I'm in the terminal I created this mongos services. yl file which is my Docker compos file with
16:29
those two Services defined here so exactly the same code that you just saw we have our credentials all our
16:35
environment variables defined and since this is a yl format please make sure that your indentations are correct
16:42
because yl is a very simple language but it's very strict on indentation so the
16:47
services need to be on the same level and then inside that service you need to have correct indentation for the
16:53
configuration attributes so now compared to the docker commands it's going to be easier for me to go here to this file
17:00
first of all see what services I'm running with what configuration edit those make any changes add any new
17:06
services that I want to run and now let's actually execute this Docker compos file and see how it works back to
17:13
my warp terminal I'm actually going to stop all the containers because we want
17:21
to start them using Docker compost so that's the first one
17:29
let's stop them we can actually remove
17:34
them and we can also
17:46
remove the dock
17:52
Network and there you go so we have a clean State no containers running and
17:58
now how do we execute a Docker compost file with Docker compost good news is if you have Docker installed on your
18:05
computer that means you automatically also have Docker compose installed so you don't have to do that separately
18:12
that means we should have Docker compose command already available as part of
18:17
Docker and Docker compos takes one attribute which is the file name
18:25
Services there you go and the command which is up which basically
18:31
means go through the docker compost file provided here and Run start all the
18:37
services configured right here so let's execute this and we're going to see the
18:43
result awesome so now there are a couple of interesting things that I want to point out and highlight in the output
18:50
that we got and also explain some of the interesting Concepts behind so let's go through them one by one I'm going to
18:56
scroll all the way up to the beginning of the output which is right here when we executed Docker compose command the
19:02
first one is I mentioned that Docker compose takes care of creating a
19:07
dedicated Network for all the containers and here we see in the output that it
19:12
actually created Network called projects uncore default so this is the name of
19:18
the network and it's going to run those two containers in that Network so if I open another terminal and if I do Docker
19:25
Network LS we're going to see projects default network was created another
19:31
interesting thing to point out is the container names for those two containers so in the docker compose we actually
19:38
called those services mongodb and Express however as you see Docker compose actually added a prefix projects
19:46
and a suffix at the end to each service so this is basically the folder that
19:53
contains the docker compos file where the docker compos file is located as you see right here so Docker compose always
20:00
takes the name of the folder where the docker compose file is executed and it
20:06
uses it as a prefix of the container and then you have one as a suffix so we have
20:12
one instance of each container and that's how the containers are called and we can also check our
20:19
containers and here you see the names projects mongodb
20:26
1 another interesting thing to point out is that you see that the logs of those
20:31
two containers are actually mixed so we have the mongod be logs Express
20:36
then mongod be again and so on because we're starting both containers at the same
20:43
time so if you had 20 Services defined here they will all start at the same time and you will see the logs basically
20:49
just mixed together on Startup however when you have multiple Services where
Control Startup Order
20:55
some Services actually depend on the others in our case Express depends on mongodb because it cannot establish a
21:02
connection the initial connection with the service until mongodb is fully up
21:08
and running so we may have such dependencies or we may have an application our custom web application
21:15
that also needs to connect to the database when we actually start the application to fetch some initial data
21:21
and so on however if the database is not up and running when the application starts the application will fail with an
21:28
error because it won't be able to connect to the database because it's not ready for the connection yet and you may
21:34
have lots of such dependencies when you're running multiple Services as part of one application and this is something
21:41
that you can Define in Docker compose with a depends on attribute so you can explicitly say this service actually
21:48
needs to wait for another service or container to be fully up and running
21:53
until this container is created with a very simple dependson attribute so basically we can say the express
22:01
service depends on and we can have multiple dependencies so for example we can say an application depends on two
22:07
different databases to start plus an authentication Service so all of those should be up and running until we start
22:13
the application because otherwise it's not going to be able to connect to those on the initial startup so dependon takes
22:19
a list of the services and it basically says wait until all the dependent
22:26
services are fully up and run running before you start this service so we can fix it very easily using this attribute
22:34
and now since we have both Services up and running again I'm going to refresh here and we should see Express
22:41
accessible from the browser and we can actually do something here so we can change something in the database so for
22:47
example I can create a mydb database and inside that I can create my
22:55
collection collection I'm very bad with with names and not very creative so that's all we got we have my DB and my
23:02
collection and this actually creates those in the actual mongodb database
23:08
cool and if I go back to the terminal we should actually see all these change logs from Express and in mongodb
23:15
basically logs new entries in the database that it
23:21
created cool now what do we do if we want to stop those containers or maybe
Docker Compose Commands (Up and Down vs Start and Stop)
23:27
we want to change some configuration in do compose and restart
23:33
those containers right now since we have the dock compos process running in the terminal we're going to need to do
23:39
contrl c to basically break out of the process and this is going to stop both
23:44
of the containers however just like with Docker run commands we have the detached mode we can actually run Docker compose
23:52
in the detached mode like this so we'll start the containers in the background
23:58
however now if we want to stop the containers we could stop them using Docker stop
24:04
commands and providing the ID of the container however again if we have 20
24:10
containers running this is not going to be a efficient way to do it and with do compose it's also very simple
24:20
actually instead of up we do down and what this will do if we have 20 Services
24:25
defined here that are running as containers it's going to go through all of those and it will actually not only stop those
24:33
containers but also remove them so now if I do Docker PS a so this shows
24:41
running and stopped containers so all the containers in any state you see that we have no containers because they have
24:47
been removed completely and you also see the network itself was removed so
24:52
basically with Docker composed down you have a very easy way to clean up the entire state so you don't have any
24:59
leftovers of containers and networks that you created previously everything will be completely removed however when
25:06
you're running containers and when you make changes like we did in the database for testing you may want to retain those
25:13
changes the state or the data in those containers so you don't want to completely remove the containers you
25:19
just want to stop them and then restart them and as you've learned in the docker crash course containers are ephemeral
25:26
they have no persistence so all the data is gone when you remove the container
25:31
because by default it doesn't have any persistence unless you configure that persistence with volumes however if you
25:38
just stop the containers and restart them you will still have the state and data because the container itself was
25:43
not removed it actually stayed locally so to demonstrate that let's do up
25:50
again and with Docker compos you can execute stop command which simply stops
25:55
the containers and if I do docker PSA you see that the containers are still
26:01
available locally they're just not running they're in an exited
26:06
status and we can start them again using Docker compose start
26:13
command and if we refresh our mydb database and collection are gone we can
26:20
create them again like
26:26
this we can restart using Docker compose and
26:34
the data should still be there so that's basically the difference between up and down commands compared to start and stop
26:41
and obviously both have their different use cases and one more thing since we are executing Docker compose
26:48
commands very often like this one for example we can actually go ahead and bookmark this like
26:56
this so if we have too many commands in the
27:02
history for example and if we are scrolling around which basically creates this visual marker and you can just
27:09
click inside and it jumps directly to that command we can then copy that
27:14
command and execute here perfect so now before we move on to the next part of
Connect own web application
27:21
this demo where we connect our own custom application to the mongodb
27:26
database and run it also as part of Docker compos service let's go to the
27:33
database and in our new collection let's actually create a new document that our
27:39
application is going to need it's going to be a very simple document let's add
27:44
two more attributes here so we're going to have let's call this my ID again as you see I'm very uncreative with names
27:52
so this is going to be an ID that we can reference in addition to this generated
27:58
ID and then we're going to have the actual data which is going to be a string and we're just going to write here some Dynamic data loaded from DB so
28:08
when we load this from our application we know that it's coming from the database so I'm going to save this
28:14
document in the collection you see it was created here here are the values the generated ID my ID literally my ID and
28:22
this data um text okay and we're going to make this a little bit more
28:28
interesting so we're going to use a custom JavaScript application which is a super simple application with just one
28:34
file that simply connects to the mongodb database and displays the data in the
28:39
browser so we can see some of the concepts in action and we're going to containerize our JavaScript application
28:47
and run it as part of the docker compos services and of course I'm going to provide the link to the git repository
28:54
where this JavaScript application is hosted in the the video description so you can just clone it locally to follow
29:01
along and by the way you will also find the docker compost file in that repository so all the code that we write
29:07
in this demo will be there so I have cloned my own application locally in the
29:15
projects I've called it Docker compos crash course so let's switch inside and
29:22
to show you how simple the application is I have opened it in the visual studio code so I don't have the docker compos
29:28
here yet this is the entire application we basically have the server JS which is a node.js backend and index.html which
29:37
has the style the JavaScript code which is basically just one function and the
29:43
HTML code in one file so the simplest app ever created so first of all you
29:49
don't need to understand any part of this code we're just going to concentrate on the configuration and the
29:56
dockerization part part of this app so even if it's simple app you don't need to understand the code but just to run
30:02
through the logic on a high level this backand basically connects to the
30:07
database logic we have this index.html file which shows two lines of data we
30:13
have some static data which is hardcoded in the file itself and then we have data
30:20
that is supposed to come from a database so this is empty so we're going to set
30:25
it dynamically from the data that we get from the database which is going to be
30:31
this data right here and the way we do that is in this JavaScript section when we
30:38
load this index HTML page it basically the front end basically sends a request
30:45
to our server JS backand and it says fetch the data and in server JS we
30:52
accept that request right here we connect to the database base using this
30:58
logic right here and now that we are using my DB and my collection as the
31:04
database and collection name that's why we created them in the database and it connects to this collection and it
31:11
basically grabs the element that has this key value pair inside my ID one so
31:18
it's going to get this data here from the collection and it's going to send
31:23
that the whole object back to the front end as a response and then we're going
31:28
to grab the data attribute from that response that's the data this is the
31:34
value of the data and we're going to set it as the value for this second line so that's how the whole thing is going to
31:40
work and in order to connect to the database because remember we actually set username and password on mongodb so
31:47
our application needs to have that same username and password just like the Express container had to have
31:55
those credentials so we are providing those also as environment variables so
32:00
just like Express had to receive those values as environment variables
32:05
our application is also going to receive those as environment variables with these names so Mong to be username M Tob
32:13
password and we use those to connect to the database that's the entire logic so now our goal is to take this application
32:20
to build a Docker container out of it using the docker file blueprint which is
32:25
right here also very simple simple because it's a nodejs application we use node as a base image uh we basically
32:32
take the code that we have here in the app folder we copy it into the image we
32:38
run npm install to download the dependencies inside the
32:43
image and then we just start the application using node command which comes from here and server.js file which
32:52
is this file right here so it starts the application on
32:57
Port 3000 and logs this as a first log of the
33:02
application so we want to use Docker file and again you learn Docker file in
33:08
the docker crash course how to use it so all this should be familiar to you so we want to build our custom JavaScript
33:15
application as a container and run it as part of Docker compose along with
33:21
mongodb and Express Services that's the goal how do we do that first
33:26
of all we need to copy that Docker compos that we created into this application code and remember another
33:33
interesting point to highlight here Docker compose is part of the application code so developers work on
33:39
Docker compose just like they work on Docker file and other parts of the application code which is the best practice to have all this logic together
33:46
in one repository instead of scripts and commands spread on laptops and computers
33:52
of different developers everything is in a central place so we created the
33:57
this Docker compose file in the projects folder and we want to copy this into
34:03
this folder so let's do a simple
34:11
copy there you go and here we have our Services yl.
34:19
compost file and as I said we want to add our application as a third service
34:26
which is going to run as a container service but we don't have the image yet so we need to build the image as well in
34:32
do compost what you can actually do you can Define both in one configuration so
34:38
we can build and then start the container with Docker compose so right here I'm going to add the service for
34:45
our nodejs application and let's call this my app because great with names and
34:53
instead of image because we want to build that image first we're going to Simply provide build attribute and the
35:01
build context which is current directory and this basically points to where the
35:06
docker file is located as well as the entire build context for that image and
35:12
the rest of the configuration is going to be the same as for other services so we have the ports in our case we're
35:19
starting this application on Port 3000 so that's what we're going to Define
35:25
right here so Port 3000 inside the container we're going to bind it on 3,000 on our host and as we saw we have
35:32
the environment variables defined here as well so we need to set
35:39
those so that our application will be able to connect to the database using
35:45
those credentials and that's basically the entire configuration this will build
35:51
our node.js application image using Docker file as a blueprint for the image
35:58
and it will start it as a container on this port and pass in those environment
36:03
variables that our application will read here and use it to connect to the database now we don't have to configure
36:11
depend on here because the application doesn't actually connect to the database when it starts up so this is the startup
36:18
logic so here we don't have any connection it only connects to the database when we load the application in
36:25
the front end in the browser this function gets executed or this script gets executed and because of that we don't
36:32
need to do depends on here and now let's go back to the terminal let's first of
36:39
all see whether we have containers running let's get
36:45
our Command to stop those containers so we're not going to remove them because
36:50
we need the database collection and the data inside for our application and now
36:56
I'm going to go into the docker compose crash course folder where we have the
37:01
new Docker compose and I'm going to execute Docker compose up and let's
37:10
execute and as you see it is actually building the new Docker image from the
37:15
Noe base image and that was actually pretty fast and now we should have all three containers running let's check
37:24
that and we have really bad names for our containers because the name of the folder is very descriptive large name
37:33
which was used as a prefix for containers but that's fine and this were
37:38
created from scratch so
37:43
our previous containers with this prefix are not
37:49
actually running instead it created the new ones and that brings me to another
37:54
concept which is you can actually over IDE the value that is used as a prefix
37:59
so maybe you want to reuse the same containers but you have moved the docker compost file to another location so
38:06
let's actually remove those containers that we
38:13
just started like
38:18
this so now we only have those two and the way we can
38:24
override is use using a flag on Docker compose so we can add an additional flag
38:32
here minus P or also project name so essentially the name of
38:39
the folder is assumed to be the project name so we can overwrite that project name value using this flag and we can
38:47
call this projects which was the previous one like this and let's start
38:53
the container let's do drps as you see our
38:59
old instances of mongodb and Express were restarted instead of new
39:05
ones being created plus the network called projects default that was already there and that means if I refresh this
39:16
we still have our MB and my collection and the data inside for our application
39:22
which means if I visit the application on Local Host 3000 which should see our
39:28
awesome application and Let me refresh this once again so we can see the network traffic
39:35
here we refresh so this was the fetch data request which we execute right here that
39:44
basically returns this object that we created here from in the
39:51
database back to the front end so if we go to preview or our response we see
39:58
this object with my ID one this is the ID from the database and the
40:05
data some Dynamic data loaded from DB and we're using that to set this line
40:13
right here so if I actually went there and changed
40:18
this like this and let save I'm going to refresh again you see that now we get this
40:26
updated data from the database so the entire connection Works our application is connected to the database and
40:34
displays that information right here now I mentioned that dock compose is part of
Variables in Docker Compose
40:40
the application code which means it gets committed and stored in a git
40:46
repository so that everyone can work on it it's available for the entire team if a new engineer joins the team and they
40:53
download the code they have docu compos so they know know exactly what services are running as part of that application
40:59
and they can easily start that locally however that also means that it's really
41:04
bad that we are hardcoding our secret credentials in the docker compost file
41:10
because the best practice for security is that you shouldn't hardcode any sensitive data in the application code
41:18
so it doesn't end up in the git repository and even if you remove it later if you accidentally checked it in
41:25
and removed it it's still going to in the commit history so you shouldn't have any hardcoded values here so how do we
41:31
solve this because we need those credentials to be passed on to Services well for that we can actually use
41:36
variables or placeholders in Docker compost instead of the actual values and
41:42
we can set the values of those variables as environment variables on the operating system so let's see how it
41:48
works first of all we're going to remove all those hard-coded values and instead we're going to define the variables in
41:55
Docker compos which has a syntax of dollar sign and then curly braces and
42:00
inside that we can name the variable whatever we want I'm going to call this admin user because it's the admin
42:07
user in mongod to be and by the way this could be lowercase you can call this really what you want but I'm using a
42:14
standard environment variable name convention here with all upper cases so we have the admin user let's call this
42:21
admin pass for password and we're going to reuse use those
42:31
everywhere which is another advantage of using variables because if you change those values like if you change the
42:37
password value for example you just have to change it or set it once and it automatically gets updated everywhere so
42:43
now this do compost does not have any hardcoded sensitive data and it's safe to check it in the G repository however
42:51
we still need to set those actual values so to test that let's go back to the
42:57
terminal first of all I'm going to stop
43:03
those stop the containers so we can test that everything works and on the first Docker compos command execution we get a
43:10
warning that says the variables are not set the containers were stopped however
43:15
we need to set those as variables in our terminal session
43:21
so we set them here export admin user
43:27
let's set the other
43:32
one like this and the same way as we did with up command we actually need to
43:39
specify which containers we're stopping so by default it's going to look for containers that start with this name the
43:46
name of the folder so we need to overwrite that projects tag again and there you go and I'm actually
43:53
going to bookmark this one as well
44:01
like this and if we refresh we should see that the pages are
44:09
not working because the containers are stopped and then let's start them
44:15
again and if we start them again with those environment variables
44:21
set everything should work same as before
44:26
let's wait there you go now I want to mention here that Docker compos actually has a concept of Secrets which is
Docker Compose Secrets
44:34
another functionality to manage the secrets especially when you're running do compos in a production environment
44:39
which is exactly for this use case where you need to pass in credentials or any sensitive data to the services defined
44:47
in Docker compose so you can use Docker compose Secrets as an alternative to this method basically awesome we have
44:53
just learned the fundamentals of docker compose and more importantly you understand its core use case and by the
45:00
way I want to highlight the importance of learning tools like Docker and Docker compos or generally cloud and devops
45:07
Technologies because nowadays it is becoming more and more needed for software developers to learn those tools
45:13
to become more valuable in their roles especially in the current tense job
45:18
market where we have layoffs and companies hiring less as more and more companies are adopting devops it is a
45:25
great way to Stand Out Among developers who only focus on programming and are
45:31
not interested to learn new Concepts and tools that are being adopted in the industry so I think it's definitely more
45:37
important than ever to educate yourself keep learning and with devops or Cloud engineering skills you will definitely
45:43
be ahead of 90% of developers in fact most of our devop boot camp students are
45:50
actually software developers or software Engineers since many companies do not have a separate devops engineer role but
45:57
often their responsibility lies on senior developers to set up the devops processes like release pipelines for
46:03
example so even if you are a junior software engineer learning devops and Cloud skills and technologies will
46:10
absolutely accelerate your career to a senior engineer so if you want to get a complete education on devops to take
46:18
over devops tasks at your work then definitely check out our devops boot camp you will learn various Technologies
46:25
from zero to an advanced level to be able to build real world Davos processes
46:32
at your job and if you need some guidance before you can also contact us there with your questions so check out
46:38
the information below and let's move on to the next part so now we are building and running
Use image from private repository
46:44
our JavaScript application as a container along with mongodb service and
46:50
the mongodb UI but usually that's a testing environment as you learn in the docker crash course eventually you want
46:56
the JavaScript application your custom application container to be stored centrally in a Docker registry or rather
47:04
the image to be stored in Docker registry so we can start and deploy it as a container on the end environment on
47:10
a actual deployment server where end users will access it so we need to build the image and push that to the
47:16
repository like a dockerhub repository or whatever other Docker repository want
47:22
and now the interesting question is after we push the image to private Docker repository how do we reference
47:28
our Custom Image from our private Docker repository in Docker compose and also
47:34
note that when we run this on an actual deployment server we're going to copy
47:40
the docker compose on that server where we have Docker and Docker compose installed and when we run this Docker
47:45
compost file or execute this it will go through all the services and it will pull all the images defined here and run
47:51
them as containers with all this configuration so we pull the official images from docker H public repository
47:57
and any custom images from the private repositories so let's actually see how it works it's actually very very easy
48:04
and again building image pushing it to the repository the whole thing you should already know it from the docker course so this should be a refresher for
48:12
you so let's actually see that in action right here so first of all I'm going to
48:17
log into my dockerhub account and I'm actually going to create a new private repository in dockerhub
48:24
like this let's call this my app because it's generic I may use it for some other
48:31
demonstration later so there you go and now we're going to
48:38
build our image using the docker file and we're going to push that image to
48:44
this specific private repository so let's execute those commands I'm going to build using Docker
48:51
build command I'm going to tag this and this is again a refresher from Docker
48:56
course we need to take the image with the name of the repository so that Docker knows on push command which
49:03
repository to push that image to so that's going to be the entire name so
49:08
the image name itself includes the repository name and we're just going to tag it with a simple
49:15
1.0 and we need to provide the build context which is the current directory where Docker file is located and that's
49:22
basically it let's execute again super first let's list all the images so
49:30
we can see what we have built locally and there you go this is our image with
49:35
an image tag and this is exactly the image we want to push now to the private
49:41
reposer and you know when we want to push or pull from a private repository we need to be logged in to that
49:47
repository so we need to do Docker login and the username is actually your
49:53
dockerhub username name and dockerhub
49:59
user password and this is actually different for other Docker repositories
50:05
so if you have a ECR or some other Docker repository the process may be different with dockerhub it's very
50:12
simple that's why I use it for the demos mostly so we are now logged in to
50:17
dockerhub and what I can do now is basically push that image that we just
50:24
created using simple Docker push and the image full name with the
50:32
tag and there you go and if I refresh we should see one
50:40
tag here 1.0 for our my app image repository perfect and one thing I
50:46
wanted to show you here is that whenever you are building and pushing an image you basically have the same commands all
50:53
the time for the specific action you build the image you log in if you're not logged in already you push the image and
51:00
so on and I have actually used a feature called workflows in workp for these kind
51:05
of use cases which can be really helpful if you want to if you have a set of commands that you always need for the
51:12
same type of workflow you can basically Define that as one unit so you can group
51:17
those commands in one unit called the workflow and you can save it here and
51:23
whenever you need that you can just execute all those commands with one click which I personally found super
51:29
cool so in warp drive you have some options here you create a new
51:34
workflow and I'm going to call this Docker push and here you can list the
51:40
different commands basically so let's do Docker login and we have
51:46
username which was this one right here and obviously we don't want to provide a password hardcoded here so we're going
51:53
to pass that as very variable or
52:00
argument and we're going to read that from the standard input again this is a
52:05
refresher from Docker this is how should use Docker login so you don't type in the password directly and with worp you
52:13
can actually use arguments like this so whenever you run
52:18
this command or list of commands before it runs it will actually tell you how you should fill out this argument so
52:24
we're going to use an AR arent here and then after Docker login we're going to do Docker build like we
52:31
did with an image tag we can also make this an argument
52:38
let's make this an argument number two and then push
52:45
that like this you can also set default values let's actually do 1.0
52:51
here and this way you don't have to type out all the commands for the same
52:56
workflow so let me check all these commands so we need a build context at the end and the rest looks pretty good
53:05
and let's save the workflow and the way it works is now I have the workflow right here and whenever I need that workflow
53:13
to execute I just click on it and it fills out the terminal basically with
53:19
all these commands and it highlights the the arguments that I need to set so I'm
53:24
actually going to put my password here as an argument
53:30
and then let's say we want 1.1 as a second argument and we can execute all
53:36
the commands like this and this will actually have pushed another tag with
53:41
1.1 so this is a cool feature that you can use on warp to make your life a little bit more convenient and that
53:48
means now we have our image with two different Texs in a private
53:54
Repository and now if we go back to the dock compost we don't need to build it
53:59
locally we can again this is convenient for testing because when you're testing
54:05
on a local environment as a software developer as an engineer you may want to just do very quick local changes in a
54:11
Docker file or in application test it quickly and you don't want to be building and pushing and pulling image
54:18
all the time so this is a very good functionality for local testing however
54:23
on an end environment obviously we need to Define an image that comes from a repository maybe we have scanned that
54:30
image already and made sure that it's secure and properly configured and so on
54:35
and now we want to actually use it and how do we reference our Custom Image
54:40
from a private repository in Docker compose very simple basically do it just like any
54:47
other image in dockerhub or any other repository like this with a specific
54:52
image tag that is available let's do 1.0 and how will Docker compos be able to
54:57
pull that image from a private repository or basically authenticate with the private repository to pull the
55:03
image it actually uses the same Docker login that we use to do Docker push so
55:09
Docker login basically creates after successful login authentication with the
55:14
docker Hub it actually creates a Docker Json file locally that creates the
55:20
authentication credentials or tokens in that file and Docker compos in the background is using Docker to run those
55:28
containers so it's going to be the exact same process pulling or pushing the images from Docker compose so that means
55:35
if you have done Docker login already to that repository then you should be able to pull any images defined in Docker
55:42
compose from that repository that means that's the configuration this should work now in order to test that let's
55:50
actually stop our containers
56:02
so they're all stopped and I'm actually going to remove the application
56:07
container because we want to simulate that the container is recreated from the
56:12
new image that we pull and now if we
56:22
do up again in DET mode and as you see my app image was pulled
56:31
and the container my app was started from that if we check the running
56:37
containers we see that this is the image that was used to create this container
56:45
awesome and again we can check that our application still works and there you go
56:51
that's how we can reference our Custom Image from a Docker repository in the
56:58
docker compose and in case when you're executing those commands so let's say
57:03
we're doing Docker build and you forget one of the arguments or use a wrong flag
57:10
and so on first of all you get an error but you can also do a troubleshooting feature
57:17
within the terminal to actually give you a pretty good tips and notes on what the
57:24
error actually is because sometimes we make spelling mistakes sometimes we forget an argument or whatever so it
57:31
could be helpful for a tool to actually tell you what the actual problem is so you can fix it and warp has this AI
57:38
assistant which is pretty cool so for this specific error if I open this warp
57:44
AI which you can see on every command block so you have this bookmark and you
57:49
have this warp AI so if I click on this it actually autog generates the question
57:54
question because it knows that this is an error and you can ask it how to fix
58:00
it so you can modify your question or example and if I hit enter here it gives
58:06
me an answer that the docker build command requires an argument which should be the path to the docker file
58:12
and gives me an example with the correct one so change the directory that has Docker file and then execute this
58:19
command which has dot at the end so I found this feature also pretty cool which means if any of the commands give
58:25
you an error while you're following this demo you can actually use this to find
58:31
out what the error is about and and ideally how to fix it so this is going to help you troubleshoot your issues and
Limitations, DockeR Compose vs Kubernetes
58:38
finally I want to actually add a few very interesting and important Concepts
58:43
regarding docu compose and kind of what the next steps are so this final small
58:49
section may be really really interesting for you so basically as you see the main use case of Docker composed was to have
58:55
a central place to manage containers that were supposed to run together like
59:00
your application and all the services that it depends on and we configure all the environment variables or any other
59:06
configuration for those services in that one file and also start them in one isolated Docker Network and it makes it
59:14
super easy for us to clean up all the resources so Engineers took Docker and they containerized their applications to
59:21
a whole new scale that was not a standard before and Docker was especially perfect to use as a host for
59:29
microservice applications where you have even more applications and more containers now running in one
59:36
environment and again if you don't know about microservices I have a separate video about them but essentially it's
59:42
when you have all the services needed to run one application but split into separate micro applications or services
59:49
and they can be scaled independently and run independently as independent containers so Docker was a perfect host
59:56
for that so we ended up with lots of applications lots of microservices applications with hundreds or thousands
1:00:03
or tens of thousands of containers that is pretty much a standard nowadays such
1:00:09
a scale actually led to Docker compost actually not being able to handle such
1:00:16
large scale of containers and more importantly Engineers will have to still manually manage running and operating
1:00:22
those containers with do compose like if containers die or crash or have connectivity issues ETC you have to
1:00:30
manually detect and then debug and restart the services now Docker compose actually made some improvements on that
1:00:35
there tags like restart and so on but it's still a lot of operational effort
1:00:41
to run the containers with this kind of scale where you have thousands of them
1:00:46
using Docker compose and that's where kubernetes kind of came into the picture to solve exactly these two main issues
1:00:54
initially scaling to thousands or tens of thousands of containers with kubernetes you can basically merge
1:01:00
hundreds of servers into one huge server to deploy all the containers that belong to the same application in that
1:01:07
environment they will all run as if they were running on the same server so it naturally makes it easier to scale your
1:01:12
applications and to run thousands of instances and the second one was the automatic operations or making the
1:01:19
operations of applications easier or also called kubernetes Auto healing feature which basically manages starting
1:01:26
and restarting containers if they crash and has mechanisms to manage operations
1:01:31
of a large number of containers in an automated way when manual effort isn't
1:01:36
it's just impossible or not feasible anymore and that led to C is becoming so popular so Docker compose is kind of
1:01:44
like a intermediary step if you have smaller set of containers but with
1:01:49
today's standards when you want to work with very complex applications with a large scale then Docker compose has its
1:01:56
limits so that's where kubernetes basically comes into the picture so if you're learning this containerized
1:02:02
containerization and container orchestration Concepts then I would actually recommend to use this road map
1:02:08
of learning the docker using the docker crash course then learning the docker compose with this course like you did
1:02:16
and then you can move on to the kubernetes and if you want to learn kubernetes I also very conveniently have
1:02:21
a kubernetes crash course to get you started in kubernetes very easily so if you want to get started with that you
1:02:28
can check out any of the many videos that I have on my YouTube channel but I would recommend to start with the
1:02:34
kubernetes crash course so I hope you learned a lot of new Concepts you obviously learned Docker compose as a
1:02:40
new tool new technology thank you for watching till the end let me know in the comments how this video actually helped
1:02:47
you in your work or maybe in your job application I'm always happy to hear and read that feedback from our viewers to
1:02:54
know that my videos are helpful in actual job environment you can also share any other tips and learnings about
1:03:02
dock compose that you have from your practical experience so that other viewers can read and benefit from it as
1:03:08
well and with that thank you for watching and see you in the next video


============================================================================================
